---
title: 述职报告
description: ''
---


# 银河智学公司 2025年度阶段性工作述职报告

**汇报人：** lxx
**入职时间：** 2025年9月  
**岗位：** 测试工程师  
**所属项目：** 教师端应用（Teacher App）  
**汇报周期：** 2025年9月 - 2025年12月

---

## 一、个人简介与入职背景

本人于2025年9月正式加入银河智学公司，担任测试工程师一职。银河智学作为K12智慧教育领域的创新型企业，致力于通过科技手段提升教学效率、优化学习体验。入职以来，我快速融入团队，积极学习公司业务和测试流程，目前主要负责教师端应用的质量保障工作。

教师端应用是银河智学产品矩阵中的重要组成部分，面向一线教师用户，提供作业布置、测验组织、学情分析等核心教学场景支持。在过去的三个多月里，我深度参与了**答题卡系统**这一核心业务模块的全流程测试工作，积累了丰富的业务理解和测试经验。

---

## 二、核心业务模块介绍：答题卡作业/测验系统

### 2.1 业务背景与价值

在传统教学场景中，教师批改作业和组织测验面临诸多痛点：
- 纸质作业批改效率低、反馈周期长
- 学情数据难以量化和追踪
- 测验结果分析依赖人工统计，耗时耗力
- 错题归纳和薄弱点分析缺乏系统支持

答题卡系统正是为解决这些痛点而设计，它将传统的纸笔作业/测验数字化，帮助教师实现：
- **一键布置**：快速创建和分发答题卡任务
- **自动批改**：客观题系统自动判分
- **智能分析**：多维度学情报告自动生成
- **精准教学**：基于数据的针对性教学指导

### 2.2 任务类型体系

教师端应用的任务体系设计如下：

| 任务大类 | 任务类型 | 子类型 | 说明 |
|---------|---------|--------|------|
| 作业任务 | 标准作业 | - | 基于题库资源的常规作业 |
| 作业任务 | **答题卡作业** | 正确率模式 | 仅统计正误，适用于练习巩固 |
| 作业任务 | **答题卡作业** | 计分模式 | 支持分值设置，适用于阶段检测 |
| 测验任务 | 标准测验 | - | 基于题库资源的随堂测验 |
| 测验任务 | **答题卡测验** | 正确率模式 | 快速测验，关注正确率 |
| 测验任务 | **答题卡测验** | 计分模式 | 正式考试，需要精确计分 |
| 资源任务 | 资源下发 | - | 课件、视频等学习资料分发 |
| 课程任务 | 课程学习 | - | 结构化课程内容推送 |

### 2.3 两种评分模式对比

**正确率模式（isScoreMode=0）**
- 适用场景：日常练习、课后巩固
- 核心指标：正确率、错题数量
- 特点：轻量化、快速出结果
- 报告重点：哪些题错了、正确率多少

**计分模式（isScoreMode>0）**
- 适用场景：单元测试、期中期末考试
- 核心指标：得分、得分率、排名
- 特点：支持题目分值设置、多选题少选得分策略
- 报告重点：总分、各题得分、分数段分布

计分模式还支持更精细的配置：
- `isScoreMode=1`：少选得一半分（适用于多选题）
- `isScoreMode=2`：少选得N分（可自定义少选时的得分）

---

## 三、业务数据流转全景图

### 3.1 完整业务流程

答题卡系统的业务流程可分为五大阶段：

**第一阶段：资源准备**
```
教师进入"我的资源" → 点击"新建答题卡" → 填写基本信息（名称、年级、学科）
→ 添加题目分组（如：一、选择题；二、填空题） → 逐题设置（题型、选项、正确答案）
→ 选择评分模式（正确率/计分） → 如选计分模式则设置各题分值
→ 保存答题卡 → 资源进入"我的资源"列表
```

**第二阶段：任务布置**
```
教师进入"布置任务" → 选择"答题卡作业"或"答题卡测验"
→ 选择布置对象（可多选班级、可精确到个别学生）
→ 从资源列表选择答题卡（或新建/复用已有答题卡）
→ 设置任务名称、截止时间 → 设置答案发布策略（立即/提交后/指定时间）
→ 确认布置 → 任务推送至学生端
```

**第三阶段：学生作答**
```
学生在学生端接收任务 → 进入答题界面 → 逐题作答
→ 支持文字输入、图片上传、手写板等多种作答方式
→ 提交答案 → 系统记录作答数据（答案内容、用时、提交时间）
```

**第四阶段：教师批改**
```
教师进入"作业管理" → 查看任务列表 → 进入待批改任务
→ 系统自动批改客观题（选择题自动判分）
→ 教师批改主观题（填空题、解答题需人工判断）
→ 支持"按题批改"（同一题看所有学生）或"按人批改"（一个学生看所有题）
→ 批改过程自动保存草稿 → 全部批改完成后提交
```

**第五阶段：报告分析**
```
批改完成后系统自动生成报告 → 班级整体统计（完成率、平均分/正确率）
→ 学生个人表现（得分、排名、用时） → 题目维度分析（正确率、错题分布）
→ 支持导出Excel报告 → 教师可据此进行针对性讲评
```

### 3.2 数据流转核心节点

| 阶段 | 数据输入 | 处理逻辑 | 数据输出 |
|------|---------|---------|---------|
| 创建答题卡 | 教师配置信息 | 表单校验、数据结构化 | AnswerSheet资源对象 |
| 布置任务 | 答题卡ID+布置对象 | 生成任务记录、推送通知 | Task任务对象 |
| 学生作答 | 学生答案数据 | 格式化存储、时间记录 | StudentAnswer记录 |
| 自动批改 | 答案+标准答案 | 比对判分、正误标记 | 客观题批改结果 |
| 教师批改 | 主观题答案 | 人工评判、分值录入 | EvaluationRecord记录 |
| 报告生成 | 所有批改结果 | 统计聚合、指标计算 | 班级/学生/题目报告 |

---

## 四、参与测试的需求版本详情

### 4.1 教师端 v1.3 - 我的资源_答题卡

**需求背景：**
为教师提供自主创建答题卡的能力，解决现有题库资源无法满足个性化命题需求的问题。

**功能清单：**
| 功能点 | 详细描述 |
|-------|---------|
| 答题卡列表 | 展示教师创建的所有答题卡，支持搜索、筛选、分页 |
| 新建答题卡 | 填写名称、选择年级学科、添加题目分组和具体题目 |
| 编辑答题卡 | 修改未下发的答题卡内容（已下发的禁止编辑） |
| 删除答题卡 | 删除未下发的答题卡（已下发的禁止删除） |
| 复用答题卡 | 基于已有答题卡快速创建新答题卡，保留题目结构 |
| 预览功能 | 预览答题卡整体效果，确认无误后保存 |

**题型支持：**
- 选择题（单选/多选）：支持2-8个选项配置
- 填空题：支持多空设置，每空独立判分
- 解答题：支持图片/手写板作答

**我的测试工作：**
- 编写答题卡创建/编辑/删除的完整测试用例
- 验证各种题型配置的正确性
- 测试已下发答题卡的编辑/删除限制逻辑
- 执行复用功能的边界场景测试
- 提交并跟踪多个UI和逻辑缺陷

### 4.2 教师端 v1.3 - 布置答题卡作业/测验任务

**需求背景：**
打通答题卡资源与任务系统的链路，让教师能够将答题卡布置给学生完成。

**功能清单：**
| 功能点 | 详细描述 |
|-------|---------|
| 布置对象选择 | 支持选择单个/多个班级，支持精确到学生个人 |
| 答题卡选择 | 从我的资源中选择已有答题卡，或现场新建 |
| 任务类型切换 | 支持布置为"作业"或"测验"两种类型 |
| 时间设置 | 设置开始时间、截止时间 |
| 答案发布策略 | 提交后立即可见/任务截止后可见/指定时间可见 |
| 布置确认 | 汇总展示布置信息，确认后下发任务 |

**我的测试工作：**
- 设计布置流程的端到端测试方案
- 验证多班级、多学生的布置场景
- 测试时间设置的各种边界情况
- 验证答案发布策略的生效逻辑
- 执行布置流程中断与恢复的异常测试
- 与学生端联调验证任务下发的完整性

### 4.3 教师端 v1.4 - 答题卡2期（计分模式）

**需求背景：**
一期的正确率模式无法满足考试场景需求，需要支持更精细的分值设置和得分统计。

**功能清单：**
| 功能点 | 详细描述 |
|-------|---------|
| 计分模式开关 | 答题卡编辑时可选择开启计分模式 |
| 题目分值设置 | 每道题可设置分值，支持0.5分精度 |
| 少选得分策略 | 多选题可配置少选时的得分规则 |
| 得分统计 | 报告页展示得分而非仅正确率 |
| 分数区间分布 | 统计各分数段人数分布 |
| 得分排名 | 学生列表按得分排序，显示班级排名 |

**模式切换测试重点：**
- 正确率模式 → 计分模式：验证分值设置提示
- 计分模式 → 正确率模式：验证分值清空确认
- 已下发答题卡：验证模式修改禁止逻辑

**报告展示差异验证：**
| 指标 | 正确率模式 | 计分模式 |
|------|-----------|---------|
| 核心指标 | 平均正确率 | 平均得分 |
| 学生排序 | 按正确率 | 按得分 |
| 题目统计 | 正确人数/错误人数 | 平均得分/得分率 |
| 导出内容 | 各题正误 | 各题得分 |

**我的测试工作：**
- 设计计分模式的完整测试矩阵
- 验证0.5分精度的分值设置与计算
- 测试少选得分策略的各种组合场景
- 验证报告页面在两种模式下的差异化展示
- 执行模式切换的数据一致性测试
- 验证分数统计和排名计算的准确性

---

## 五、测试工作成果

### 5.1 测试用例产出

| 需求版本 | 用例数量 | 覆盖模块 |
|---------|---------|---------|
| v1.3 我的资源_答题卡 | 约50+ | 创建、编辑、删除、复用、预览 |
| v1.3 布置答题卡任务 | 约40+ | 对象选择、资源选择、时间设置、布置确认 |
| v1.4 计分模式 | 约60+ | 分值设置、得分计算、报告统计、模式切换 |

### 5.2 缺陷发现与跟踪

| 缺陷等级 | 发现数量 | 已修复 | 关闭率 |
|---------|---------|-------|-------|
| 严重（P0） | 2 | 2 | 100% |
| 主要（P1） | 8 | 8 | 100% |
| 次要（P2） | 15 | 15 | 100% |
| 建议（P3） | 10 | 8 | 80% |

**典型缺陷案例：**

1. **【P0】计分模式下多选题少选得分计算错误**
   - 现象：配置少选得一半分后，实际得分与预期不符
   - 原因：后端计算逻辑未正确处理小数精度
   - 影响：导致学生成绩统计不准确
   - 状态：已修复并验证通过

2. **【P1】已下发答题卡仍可进入编辑页面**
   - 现象：点击已下发答题卡的编辑按钮，能进入编辑页
   - 原因：前端限制逻辑遗漏
   - 影响：可能导致数据不一致
   - 状态：已修复并验证通过

3. **【P1】批改进度中断后无法恢复**
   - 现象：教师批改一半后关闭页面，再次进入从头开始
   - 原因：批改进度未做本地缓存
   - 影响：增加教师重复工作量
   - 状态：已修复，新增本地缓存机制

4. **【P2】报告导出Excel文件名固定为"报告.xlsx"**
   - 现象：导出的报告文件没有区分任务名称
   - 原因：导出时未动态生成文件名
   - 影响：多次导出后文件难以区分
   - 状态：已修复，文件名包含任务名称

### 5.3 测试执行情况

| 测试阶段 | 执行轮次 | 通过率 |
|---------|---------|-------|
| 冒烟测试 | 每次提测 | 95%+ |
| 功能测试 | 2-3轮 | 首轮85%，终轮100% |
| 回归测试 | 1-2轮 | 98%+ |
| 上线验证 | 每次发版 | 100% |

---

## 六、测试方法与策略

### 6.1 测试类型覆盖

**功能测试：**
- 正向流程测试：验证所有功能按需求正常运行
- 边界值测试：验证输入边界（如分值0.5-100、题目数量上限等）
- 异常流程测试：验证异常操作的容错处理

**兼容性测试：**
- 浏览器兼容：Chrome
- 设备兼容：PC端、Pad端
- 分辨率适配：1920×1080、1366×768、Pad竖屏/横屏

**接口测试：**
- 使用Postman验证核心接口的正确性
- 检查接口返回数据格式和字段完整性
- 验证异常参数的错误码返回

**用户体验测试：**
- 页面加载速度
- 操作流畅度
- 提示信息清晰度
- 交互一致性

### 6.2 测试流程规范

1. **需求评审阶段**
   - 参与需求评审会议
   - 提出测试视角的问题和建议
   - 识别潜在风险点

2. **用例设计阶段**
   - 根据需求文档编写测试用例
   - 用例评审，确保覆盖全面
   - 准备测试数据

3. **测试执行阶段**
   - 开发提测后进行冒烟测试
   - 冒烟通过后执行全量功能测试
   - 发现问题及时提交禅道并跟踪

4. **回归测试阶段**
   - 缺陷修复后进行验证
   - 执行回归用例确保无影响
   - 输出测试报告

5. **上线验证阶段**
   - 生产环境核心功能验证
   - 监控上线后用户反馈
   - 问题快速响应

---

## 七、团队协作与沟通

### 7.1 跨部门协作

**与产品团队：**
- 参与需求评审，从测试角度提出可测性建议
- 需求理解有疑问时主动沟通确认
- 反馈测试中发现的体验问题和优化建议

**与开发团队：**
- 提测前沟通改动范围，确定测试重点
- 缺陷描述清晰，附操作步骤和截图
- 复杂问题协助开发定位复现

**与运维团队：**
- 测试环境问题及时沟通
- 上线发版配合验证
- 生产问题协助排查

### 7.2 沟通工具与方式

- 日常沟通：企业微信
- 缺陷管理：禅道
- 需求文档：语雀
- 每日站会：同步进展和阻塞

---

## 八、自我评估与反思

### 8.1 做得好的方面

1. **快速熟悉业务**：入职一个月内理解答题卡模块的完整业务逻辑，能够独立设计测试方案
2. **用例覆盖全面**：注重边界场景和异常流程，多次发现关键缺陷
3. **沟通高效**：与开发、产品保持良好沟通，问题跟踪及时闭环
4. **责任心强**：对测试质量负责，不放过可疑问题

### 8.2 需要改进的方面

1. **自动化能力**：目前主要以手工测试为主，自动化测试能力有待提升
2. **性能测试经验**：对性能测试工具和方法了解不够深入
3. **测试左移**：可以更早介入需求和设计阶段，提前发现问题

---

## 九、未来规划与展望

### 9.1 短期目标（1-3个月）

- 持续保障答题卡及相关模块的质量
- 学习接口自动化测试，提升测试效率
- 完善测试用例库，形成可复用资产
- 参与更多核心模块的测试工作

### 9.2 中期目标（3-6个月）

- 掌握UI自动化测试框架
- 具备性能测试基础能力
- 能够独立制定模块级测试方案
- 参与测试流程优化

### 9.3 长期目标（6-12个月）

- 成为团队核心测试成员
- 对K12智慧教育产品有全面深入的理解
- 推动测试自动化建设
- 持续为产品质量保驾护航

---

## 十、结语

加入银河智学的三个多月，是充实且充满成长的时光。作为测试工程师，我深知质量是产品的生命线。感谢公司提供的平台和机会，感谢团队伙伴们的帮助和指导。未来，我将继续保持严谨细致的工作态度，在测试专业技能上不断精进，为银河智学的产品质量贡献更多力量。

**汇报完毕，敬请各位领导批评指正！**

---

*报告日期：2025年12月*


